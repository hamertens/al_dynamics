{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gpytorch.mlls import SumMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILEPATH = \"/home/hansm/active_learning/Double_pendulum/data/\"\n",
    "file_path_train_inputs = DATA_FILEPATH + 'train_inputs.csv'\n",
    "df_train_inputs = pd.read_csv(file_path_train_inputs)\n",
    "train_inputs = df_train_inputs.values\n",
    "\n",
    "file_path_train_outputs = DATA_FILEPATH + 'train_outputs.csv'\n",
    "df_train_outputs = pd.read_csv(file_path_train_outputs)\n",
    "train_outputs = df_train_outputs.values\n",
    "\n",
    "# Set the number of rows you want to choose\n",
    "num_rows_to_choose = 1000\n",
    "\n",
    "# Choose 2000 random indices\n",
    "random_indices = np.random.choice(train_inputs.shape[0], size=num_rows_to_choose, replace=False)\n",
    "\n",
    "# Select the corresponding rows from each array\n",
    "train_inputs = train_inputs[random_indices]\n",
    "train_outputs = train_outputs[random_indices]\n",
    "\n",
    "#train_inputs = torch.tensor(train_inputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    \n",
    "def train_gp(training_inputs, training_outputs, training_iterations):\n",
    "  likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "  training_inputs = torch.tensor(training_inputs, dtype=torch.float32)\n",
    "  model_list = []\n",
    "\n",
    "  for col_index in range(training_outputs.shape[1]):\n",
    "     training_output_column = torch.tensor(training_outputs[:, col_index], dtype=torch.float32)\n",
    "     model = ExactGPModel(training_inputs, training_output_column, likelihood)\n",
    "     model_list.append(model)\n",
    "\n",
    "\n",
    "  gp_model_list = gpytorch.models.IndependentModelList(model_list[0], model_list[1], model_list[2], model_list[3])\n",
    "  likelihood_list = gpytorch.likelihoods.LikelihoodList(model_list[0].likelihood, model_list[1].likelihood, model_list[2].likelihood, model_list[3].likelihood)\n",
    "\n",
    "  mll = SumMarginalLogLikelihood(likelihood_list, gp_model_list)\n",
    "\n",
    "  # Find optimal model hyperparameters\n",
    "  gp_model_list.train()\n",
    "  likelihood_list.train()\n",
    "\n",
    "  # Use the Adam optimizer\n",
    "  optimizer = torch.optim.Adam(gp_model_list.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "  for i in range(training_iterations):\n",
    "      optimizer.zero_grad()\n",
    "      output = gp_model_list(*gp_model_list.train_inputs)\n",
    "      loss = -mll(output, gp_model_list.train_targets)\n",
    "      loss.backward()\n",
    "      print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "      optimizer.step()\n",
    "\n",
    "  return likelihood, gp_model_list\n",
    "\n",
    "def gp_eval(test_inputs, model, likelihood):\n",
    "  test_inputs = torch.tensor(test_inputs, dtype=torch.float32)\n",
    "  # Set into eval mode\n",
    "  model.eval()\n",
    "  likelihood.eval()\n",
    "\n",
    "\n",
    "  # Make predictions (use the same test points)\n",
    "  with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "      \n",
    "      # This contains predictions for both outcomes as a list\n",
    "      predictions = likelihood(*model(test_inputs, test_inputs, test_inputs, test_inputs))\n",
    "      final_prediction = np.column_stack((predictions[0].mean.numpy(), predictions[1].mean.numpy(), predictions[2].mean.numpy(), predictions[3].mean.numpy()))\n",
    "      variance_lst = []\n",
    "      for prediction in predictions:\n",
    "        lower, upper = prediction.confidence_region()\n",
    "        variance = upper.numpy() - lower.numpy()\n",
    "        variance_lst.append(variance)\n",
    "  return final_prediction, np.column_stack(variance_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model, gp_likelihood = train_gp(train_inputs, train_outputs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gpytorch.likelihoods.gaussian_likelihood.GaussianLikelihood'>\n"
     ]
    }
   ],
   "source": [
    "print(type(gp_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "gp_model.eval()\n",
    "gp_likelihood.eval()\n",
    "\n",
    "\n",
    "# Make predictions (use the same test points)\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    # This contains predictions for both outcomes as a list\n",
    "    predictions = gp_likelihood(*gp_model(test_inputs, test_inputs, test_inputs, test_inputs))\n",
    "    variance_lst = []\n",
    "    for prediction in predictions:\n",
    "        lower, upper = prediction.confidence_region()\n",
    "        variance = upper.numpy() - lower.numpy()\n",
    "        variance_lst.append(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_test_inputs = DATA_FILEPATH + 'test_inputs.csv'\n",
    "df_test_inputs = pd.read_csv(file_path_test_inputs)\n",
    "test_inputs = df_test_inputs.values\n",
    "\n",
    "file_path_test_outputs = DATA_FILEPATH + 'test_outputs.csv'\n",
    "df_test_outputs = pd.read_csv(file_path_test_outputs)\n",
    "test_outputs = df_test_outputs.values\n",
    "\n",
    "test_inputs = torch.tensor(test_inputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, var = gp_eval(test_inputs, gp_model, gp_likelihood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
