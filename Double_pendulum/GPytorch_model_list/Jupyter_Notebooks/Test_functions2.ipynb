{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gpytorch.mlls import SumMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILEPATH = \"/home/hansm/active_learning/Double_pendulum/data/\"\n",
    "file_path_train_inputs = DATA_FILEPATH + 'train_inputs.csv'\n",
    "df_train_inputs = pd.read_csv(file_path_train_inputs)\n",
    "train_inputs = df_train_inputs.values\n",
    "\n",
    "file_path_train_outputs = DATA_FILEPATH + 'train_outputs.csv'\n",
    "df_train_outputs = pd.read_csv(file_path_train_outputs)\n",
    "train_outputs = df_train_outputs.values\n",
    "\n",
    "# Set the number of rows you want to choose\n",
    "num_rows_to_choose = 1000\n",
    "\n",
    "# Choose 2000 random indices\n",
    "random_indices = np.random.choice(train_inputs.shape[0], size=num_rows_to_choose, replace=False)\n",
    "\n",
    "# Select the corresponding rows from each array\n",
    "train_inputs = train_inputs[random_indices]\n",
    "train_outputs = train_outputs[random_indices]\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gp(training_inputs, training_outputs, training_iterations):\n",
    "    gaussian_likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model_list = []\n",
    "    for col_index in range(training_outputs.shape[1]):\n",
    "        training_outputs_column = torch.tensor(training_outputs[:, col_index], dtype=torch.float32)\n",
    "        exact_model = ExactGPModel(training_inputs, training_outputs_column, gaussian_likelihood)\n",
    "        model_list.append(exact_model)\n",
    "    likelihoods = [model.likelihood for model in model_list]\n",
    "    likelihood = gpytorch.likelihoods.LikelihoodList(*likelihoods)\n",
    "    model = gpytorch.models.IndependentModelList(*model_list)\n",
    "\n",
    "    mll = SumMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the Adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(*model.train_inputs)\n",
    "        loss = -mll(output, model.train_targets)\n",
    "        loss.backward()\n",
    "        print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model, gp_likelihood = train_gp(train_inputs, train_outputs, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gpytorch.models.model_list.IndependentModelList'>\n"
     ]
    }
   ],
   "source": [
    "print(type(gp_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_eval(test_inputs, model, likelihood):\n",
    "  test_inputs = torch.tensor(test_inputs, dtype=torch.float32)\n",
    "  # Set into eval mode\n",
    "  model.eval()\n",
    "  likelihood.eval()\n",
    "\n",
    "\n",
    "  # Make predictions (use the same test points)\n",
    "  with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "      \n",
    "      # This contains predictions for both outcomes as a list\n",
    "      predictions = likelihood(*model(test_inputs, test_inputs, test_inputs, test_inputs))\n",
    "      predictions_lst = [prediction.mean.numpy() for prediction in predictions]\n",
    "      final_prediction = np.column_stack((predictions_lst))\n",
    "      variance_lst = []\n",
    "      for prediction in predictions:\n",
    "        lower, upper = prediction.confidence_region()\n",
    "        variance = upper.numpy() - lower.numpy()\n",
    "        variance_lst.append(variance)\n",
    "  return final_prediction, np.column_stack(variance_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_test_inputs = DATA_FILEPATH + 'test_inputs.csv'\n",
    "df_test_inputs = pd.read_csv(file_path_test_inputs)\n",
    "test_inputs = df_test_inputs.values\n",
    "\n",
    "file_path_test_outputs = DATA_FILEPATH + 'test_outputs.csv'\n",
    "df_test_outputs = pd.read_csv(file_path_test_outputs)\n",
    "test_outputs = df_test_outputs.values\n",
    "\n",
    "test_inputs = torch.tensor(test_inputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1215078/681682463.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_inputs = torch.tensor(test_inputs, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "prediction, var = gp_eval(test_inputs, gp_model, gp_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6561, 4)\n"
     ]
    }
   ],
   "source": [
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12079695030002702\n"
     ]
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(test_outputs, prediction))\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
